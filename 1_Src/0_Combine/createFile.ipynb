{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üî¢ Description Crawler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy    as np\n",
    "import pandas   as pd\n",
    "import datetime\n",
    "import tempfile\n",
    "import subprocess\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "import gzip\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"‚ö° Start - {} ‚ö°\\n\".format(datetime.datetime.now()))\n",
    "startTime = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from langdetect import detect, DetectorFactory\n",
    "\n",
    "# # To ensure reproducibility of language detection\n",
    "# DetectorFactory.seed = 0\n",
    "\n",
    "# # Load the data from a CSV file\n",
    "# df = pd.read_csv('allDescriptions.csv')\n",
    "\n",
    "# # Print the size before dropping duplicates\n",
    "# print(f\"Size before dropping duplicates: {df.shape}\")\n",
    "\n",
    "# # Drop duplicates based on the 'pkgName' column\n",
    "# df_dedup = df.drop_duplicates(subset='pkgName')\n",
    "\n",
    "# # Print the size after dropping duplicates\n",
    "# print(f\"Size after dropping duplicates: {df_dedup.shape}\")\n",
    "\n",
    "# # Function to check if a description is in English\n",
    "# def is_english(text):\n",
    "#     try:\n",
    "#         return detect(text) == 'en'\n",
    "#     except:\n",
    "#         return False\n",
    "\n",
    "# # Apply the function to filter out non-English descriptions\n",
    "# df_filtered = df_dedup[df_dedup['description'].apply(is_english)]\n",
    "\n",
    "# # Print the size after removing non-English descriptions\n",
    "# print(f\"Size after removing non-English descriptions: {df_filtered.shape}\")\n",
    "\n",
    "# # Save the cleaned DataFrame to a new CSV file\n",
    "# df_filtered.to_csv('cleaned_file.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üì• 1) Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataframes\n",
    "az16DF = pd.read_csv(\"../../0_Data/azFiltered16.csv\")\n",
    "# Select and rename columns\n",
    "az16DF = az16DF[['sha256', 'pkg_name']]\n",
    "az16DF.rename(columns={'pkg_name': 'pkgName'}, inplace=True)\n",
    "\n",
    "# Add new columns with specified values\n",
    "az16DF['source'] = 'AZ'\n",
    "az16DF['BenjaminClass'] = np.nan\n",
    "\n",
    "az16DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from the CSV file\n",
    "mudflowDF = pd.read_csv(\"../../0_Data/4_MudFlow.csv\")\n",
    "\n",
    "# Select the necessary columns\n",
    "mudflowDF = mudflowDF[['sha256', 'pkgName', 'classID']]\n",
    "\n",
    "# Rename 'classID' to 'BenjaminClass'\n",
    "mudflowDF.rename(columns={'classID': 'BenjaminClass'}, inplace=True)\n",
    "\n",
    "# Add a new column 'Source' with the value 'MUDFLOW'\n",
    "mudflowDF['source'] = 'MUDFLOW'\n",
    "\n",
    "mudflowDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the dataframes\n",
    "maliciousDF = pd.concat([az16DF, mudflowDF], axis=0)\n",
    "\n",
    "# Print sizes of dataframes with emojis\n",
    "print(f\"üìÑ Size of az16DF      : {az16DF.shape}\")\n",
    "print(f\"üìÑ Size of mudflowDF   : {mudflowDF.shape}\")\n",
    "print(f\"üìÑ Size of maliciousDF : {maliciousDF.shape}\")\n",
    "\n",
    "# Remove duplicates based on sha256 column\n",
    "maliciousDF = maliciousDF.drop_duplicates(subset='sha256')\n",
    "\n",
    "# Print size of maliciousDF after removing duplicates\n",
    "print(f\"üìÑ Size of maliciousDF : {maliciousDF.shape}\")\n",
    "\n",
    "maliciousDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desDF = pd.read_csv(\"../../0_Data/allDescriptionsCleaned.csv\")\n",
    "desDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maldesDF = pd.merge(maliciousDF, desDF, on='pkgName', how='inner')\n",
    "\n",
    "# Drop rows where 'description' column is NaN or empty\n",
    "maldesDF = maldesDF[maldesDF['description'].notna() & (maldesDF['description'] != '')]\n",
    "\n",
    "maldesDF = maldesDF.drop_duplicates(subset='sha256')\n",
    "\n",
    "maldesDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maldesDF.to_csv(\"5_NewMalCatSet.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### üîö End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endTime = datetime.datetime.now()\n",
    "print(\"\\nüîö --- End - {} --- üîö\".format(endTime))\n",
    "\n",
    "# Assuming endTime and startTime are in seconds\n",
    "totalTime = endTime - startTime\n",
    "minutes = totalTime.total_seconds() // 60\n",
    "seconds = totalTime.total_seconds() % 60\n",
    "print(\"‚è±Ô∏è --- Time: {:02d} minutes and {:02d} seconds --- ‚è±Ô∏è\".format(int(minutes), int(seconds)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
