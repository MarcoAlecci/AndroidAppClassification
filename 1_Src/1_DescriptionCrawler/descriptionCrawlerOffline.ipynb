{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üî¢ Description Crawler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy    as np\n",
    "import pandas   as pd\n",
    "import datetime\n",
    "import tempfile\n",
    "import subprocess\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "import gzip\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"‚ö° Start - {} ‚ö°\\n\".format(datetime.datetime.now()))\n",
    "startTime = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üì• 1) Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataframes\n",
    "az16DF = pd.read_csv(\"../../0_Data/azFiltered16.csv\")\n",
    "mudflowDF = pd.read_csv(\"../../0_Data/4_MudFlow.csv\")\n",
    "\n",
    "# Select and rename columns\n",
    "az16DF = az16DF[['sha256', 'pkg_name']]\n",
    "az16DF.rename(columns={'pkg_name': 'pkgName'}, inplace=True)\n",
    "\n",
    "mudflowDF = mudflowDF[['sha256', 'pkgName']]\n",
    "\n",
    "# Concatenate the dataframes\n",
    "maliciousDF = pd.concat([az16DF, mudflowDF], axis=0)\n",
    "\n",
    "# Print sizes of dataframes with emojis\n",
    "print(f\"üìÑ Size of az16DF      : {az16DF.shape}\")\n",
    "print(f\"üìÑ Size of mudflowDF   : {mudflowDF.shape}\")\n",
    "print(f\"üìÑ Size of maliciousDF : {maliciousDF.shape}\")\n",
    "\n",
    "# Remove duplicates based on sha256 column\n",
    "maliciousDF = maliciousDF.drop_duplicates(subset='sha256')\n",
    "\n",
    "# Print size of maliciousDF after removing duplicates\n",
    "print(f\"üìÑ Size of maliciousDF : {maliciousDF.shape}\")\n",
    "\n",
    "# Display the first 2 rows of the resulting dataframe\n",
    "maliciousDF.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get data from AZ-META"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "AZ_PATH = \"../../0_Data/gp-metadata-full.jsonl\"\n",
    "OUTPUT_CSV_PATH = \"descriptions.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkgNamesList = maliciousDF[\"pkgName\"].to_list()\n",
    "print(len(pkgNamesList))\n",
    "\n",
    "pkgNamesList = list(set(pkgNamesList))\n",
    "print(len(pkgNamesList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temporary file to hold the JSON data\n",
    "with tempfile.NamedTemporaryFile(delete=False, mode='w', encoding='utf-8') as temp_file:\n",
    "    json.dump(pkgNamesList, temp_file)\n",
    "    temp_file_path = temp_file.name\n",
    "\n",
    "# Run jq command and capture the output\n",
    "try:\n",
    "    byteResult = subprocess.check_output([\n",
    "        \"jq\",\n",
    "        '--argfile', 'pkgNames', temp_file_path,\n",
    "        'select(any(.docid == $pkgNames[]; .)) | .docid + \",\" + .descriptionHtml',\n",
    "        AZ_PATH\n",
    "    ])\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"Error running jq: {e}\")\n",
    "    raise\n",
    "finally:\n",
    "    # Clean up temporary file\n",
    "    os.remove(temp_file_path)\n",
    "\n",
    "data = byteResult.decode(\"utf-8\").replace(\"\\\"\", \"\")\n",
    "\n",
    "# Split data into rows\n",
    "rows = data.split('\\n')\n",
    "\n",
    "# Prepare lists to hold the data\n",
    "pkgNames = []\n",
    "descriptions = []\n",
    "\n",
    "# Process each row to extract pkgName and description\n",
    "for row in rows:\n",
    "    if row:\n",
    "        pkgName, description = row.split(',', 1)  # Split only on the first comma\n",
    "        pkgNames.append(pkgName)\n",
    "        descriptions.append(description)\n",
    "\n",
    "# Create a DataFrame from the lists\n",
    "result_df = pd.DataFrame({\n",
    "    'pkgName': pkgNames,\n",
    "    'descriptionHtml': descriptions\n",
    "})\n",
    "\n",
    "result_df.to_csv(OUTPUT_CSV_PATH, index=False)\n",
    "print(f\"DataFrame saved to {OUTPUT_CSV_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### üîö End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endTime = datetime.datetime.now()\n",
    "print(\"\\nüîö --- End - {} --- üîö\".format(endTime))\n",
    "\n",
    "# Assuming endTime and startTime are in seconds\n",
    "totalTime = endTime - startTime\n",
    "minutes = totalTime.total_seconds() // 60\n",
    "seconds = totalTime.total_seconds() % 60\n",
    "print(\"‚è±Ô∏è --- Time: {:02d} minutes and {:02d} seconds --- ‚è±Ô∏è\".format(int(minutes), int(seconds)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
